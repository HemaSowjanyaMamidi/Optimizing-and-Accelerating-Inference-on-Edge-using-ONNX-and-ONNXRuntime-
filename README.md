# Optimizing-and-Accelerating-Inference-on-Edge-using-ONNX-and-ONNXRuntime

<p align="justify">
  ONNX is a format that offers interoperability with other machine learning frameworks and helps the developers to develop their applications in any framework and convert to other. It offers graph optimizations while converting that makes the inference faster. ONNXRuntime is an inference engine that helps us to run the ONNX Models. Deep Learning accelerators are specialized devices that helps to run the models faster. These accelerators can be plugged into the ONNXRuntime with the help of <b>Execution Providers</b>. 
